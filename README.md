# Clinical Data Quality & Outcomes Reporting (Synthetic EHR / Synthea)

## Overview
This project simulates the work of a junior healthcare data analyst supporting a clinical quality improvement / clinical research team. Using synthetic EHR data generated by Synthea, I built a reproducible pipeline to:
- ingest and validate multi-table clinical data (patients, encounters, conditions, observations)
- perform data quality checks (missingness, duplicates, invalid dates, outliers)
- load curated tables into a SQL database
- answer common clinical reporting questions using SQL
- produce a simple KPI report / dashboard-ready outputs

> Note: Data is fully synthetic (no PHI).

## Dataset
- Source: Synthea synthetic EHR generator (CSV exports)
- Tables used: patients, encounters, conditions, observations (labs/vitals), medications (optional)

## Pipeline
1. **Ingest**
   - Read raw CSVs from `/data_raw`
2. **Validate & Clean**
   - Standardize column names and datatypes
   - Filter invalid encounter date ranges
   - Handle missingness and duplicates
   - Create encounter-level features (length of stay, readmission window)
3. **Curate**
   - Output cleaned tables to `/data_clean`
4. **Load to SQL**
   - Create tables in Postgres/SQLite using `/sql/schema.sql`
5. **Analyze & Report**
   - Run analytic queries in `/sql/queries`
   - Export final tables (CSV) for dashboards in `/reports` or `/dashboards`

## Data Quality Checks (examples)
- % missing key fields by table (patient_id, encounter_id, encounter_start/end)
- duplicate patient_ids and encounter_ids
- encounters where end < start or extreme LOS outliers
- observations outside encounter windows
- implausible values (e.g., negative lab values, impossible vitals)

## Clinical / Research Questions Answered
- Data completeness by table and by month
- Average length of stay by condition category
- 30-day readmission rate overall and by age group
- Encounter volume trends over time
- Lab/vital measurement coverage per encounter (e.g., % encounters with BP recorded)

## How to Run
### Option A: Quickstart (SQLite)
1. Put raw CSVs in `data_raw/`
2. Run `python -m venv .venv && source .venv/bin/activate && pip install -r requirements.txt`
3. `python src/ingest_clean.py`
4. `python src/load_sqlite.py`
5. Run queries: `sqlite3 ehr.db < sql/queries/readmissions.sql`

### Option B: Postgres (recommended)
- Configure `.env`
- `python src/load_postgres.py`
- Run queries in `/sql/queries`

## Repo Structure
- `data_raw/` raw Synthea CSVs (or small sample only)
- `data_clean/` cleaned outputs
- `sql/schema.sql` table definitions + indexes
- `sql/queries/` reporting queries used in this project
- `src/` pipeline code
- `dashboards/` screenshots or exported visuals
- `reports/` final CSVs for dashboarding

## Results (Screenshots)
Add:
- KPI summary screenshot
- Data quality summary table
- One trend chart (encounters over time)

## Limitations
- Synthetic EHR data does not capture full complexity of real hospital EHR workflows
- Coding systems simplified (ICD mapping may be incomplete)
- Results intended for demo/training purposes only

## Next Steps
- Add unit tests for validation rules
- Add orchestration (scheduled runs) via cron/Prefect
- Expand to medication adherence or cohort selection logic
