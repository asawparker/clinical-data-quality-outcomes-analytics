# Clinical Data Quality & Outcomes Reporting (Synthetic EHR / Synthea)

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Data Source

This project uses synthetic electronic health record (EHR) data generated by :contentReference[oaicite:0]{index=0}, an open-source patient population simulation developed by The MITRE Corporation.

The dataset contains fully synthetic patient records and is free from privacy, security, and HIPAA restrictions. It is used here solely for educational and demonstration purposes to simulate real-world healthcare analytics workflows.

### Citation

Walonoski J, Kramer M, Nichols J, Quina A, Moesel C, Hall D, Duffett C, Dube K, Gallagher T, McLachlan S.  
**Synthea: An approach, method, and software mechanism for generating synthetic patients and the synthetic electronic health care record.**  
*Journal of the American Medical Informatics Association.* 2018;25(3):230–238.  
https://doi.org/10.1093/jamia/ocx079

## Overview
This project simulates the work of a junior healthcare data analyst supporting a clinical quality improvement / clinical research team. Using synthetic EHR data generated by Synthea, I built a reproducible pipeline to:
- ingest and validate multi-table clinical data (patients, encounters, conditions, observations)
- perform data quality checks (missingness, duplicates, invalid dates, outliers)
- load curated tables into a SQL database
- answer common clinical reporting questions using SQL
- produce a simple KPI report / dashboard-ready outputs

> Note: Data is fully synthetic (no PHI).

## Dataset
- Source: Synthea synthetic EHR generator (CSV exports)
- Tables used: patients, encounters, conditions, observations (labs/vitals), medications (optional)

## Pipeline
1. **Ingest**
   - Read raw CSVs from `/data_raw`
2. **Validate & Clean**
   - Standardize column names and datatypes
   - Filter invalid encounter date ranges
   - Handle missingness and duplicates
   - Create encounter-level features (length of stay, readmission window)
3. **Curate**
   - Output cleaned tables to `/data_clean`
4. **Load to SQL**
   - Create tables in Postgres/SQLite using `/sql/schema.sql`
5. **Analyze & Report**
   - Run analytic queries in `/sql/queries`
   - Export final tables (CSV) for dashboards in `/reports` or `/dashboards`

## Data Quality Checks (examples)
- % missing key fields by table (patient_id, encounter_id, encounter_start/end)
- duplicate patient_ids and encounter_ids
- encounters where end < start or extreme LOS outliers
- observations outside encounter windows
- implausible values (e.g., negative lab values, impossible vitals)

## Clinical / Research Questions Answered
- Data completeness by table and by month
- Average length of stay by condition category
- 30-day readmission rate overall and by age group
- Encounter volume trends over time
- Lab/vital measurement coverage per encounter (e.g., % encounters with BP recorded)

## How to Run
### Option A: Quickstart (SQLite)
1. Put raw CSVs in `data_raw/`
2. Run `python -m venv .venv && source .venv/bin/activate && pip install -r requirements.txt`
3. `python src/ingest_clean.py`
4. `python src/load_sqlite.py`
5. Run queries: `sqlite3 ehr.db < sql/queries/readmissions.sql`

### Option B: Postgres (recommended)
- Configure `.env`
- `python src/load_postgres.py`
- Run queries in `/sql/queries`

## Repo Structure
- `data_raw/` raw Synthea CSVs (or small sample only)
- `data_clean/` cleaned outputs
- `sql/schema.sql` table definitions + indexes
- `sql/queries/` reporting queries used in this project
- `src/` pipeline code
- `dashboards/` screenshots or exported visuals
- `reports/` final CSVs for dashboarding

## Results (Screenshots)
Add:
- KPI summary screenshot
- Data quality summary table
- One trend chart (encounters over time)

## Limitations
- Synthetic EHR data does not capture full complexity of real hospital EHR workflows
- Coding systems simplified (ICD mapping may be incomplete)
- Results intended for demo/training purposes only

## Results

### Data Quality & Completeness
- All core tables (patients, encounters, observations) contained complete primary identifiers with no missing IDs.
- Encounter timestamps (START/STOP) were fully populated across 61,459 encounters.
- Approximately **34.2% of encounters** had at least one linked clinical observation, reflecting realistic variation in encounter types (e.g., administrative vs clinical visits).

### Observation Coverage
Coverage of common vitals across all encounters:
- Blood pressure: **23.2%**
- Heart rate: **20.8%**
- Respiratory rate: **20.8%**
- Body temperature: **1.6%**
- Oxygen saturation (SpO₂): **0.5%**

Lower coverage for temperature and SpO₂ is consistent with outpatient-focused synthetic data and demonstrates the importance of coverage-aware reporting.

### Plausibility & Data Cleaning Considerations
- **34.7% of observations** lacked units, highlighting the need for unit normalization in downstream analyses.
- A substantial number of observations contained non-numeric categorical values (e.g., smoking status, social determinants), requiring type-aware handling rather than naive numeric casting.
- Plausibility checks on common vitals showed realistic value ranges:
  - Heart rate: 50–199 bpm
  - Body temperature: 36.1–42.2 °C
  - Oxygen saturation: 75–98%

These findings informed decisions on which metrics were appropriate for quantitative analysis versus categorical reporting.

