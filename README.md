# Clinical Data Quality & Outcomes Reporting (Synthetic EHR / Synthea)

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Data Source

This project uses synthetic electronic health record (EHR) data generated by :contentReference[oaicite:0]{index=0}, an open-source patient population simulation developed by The MITRE Corporation.

The dataset contains fully synthetic patient records and is free from privacy, security, and HIPAA restrictions. It is used here solely for educational and demonstration purposes to simulate real-world healthcare analytics workflows.

### Citation

Walonoski J, Kramer M, Nichols J, Quina A, Moesel C, Hall D, Duffett C, Dube K, Gallagher T, McLachlan S.  
**Synthea: An approach, method, and software mechanism for generating synthetic patients and the synthetic electronic health care record.**  
*Journal of the American Medical Informatics Association.* 2018;25(3):230â€“238.  
https://doi.org/10.1093/jamia/ocx079

## Overview
This project simulates the work of a junior healthcare data analyst supporting a clinical quality improvement / clinical research team. Using synthetic EHR data generated by Synthea, I built a reproducible pipeline to:
- ingest and validate multi-table clinical data (patients, encounters, conditions, observations)
- perform data quality checks (missingness, duplicates, invalid dates, outliers)
- load curated tables into a SQL database
- answer common clinical reporting questions using SQL
- produce a simple KPI report / dashboard-ready outputs

> Note: Data is fully synthetic (no PHI).

## Dataset
- Source: Synthea synthetic EHR generator (CSV exports)
- Tables used: patients, encounters, conditions, observations (labs/vitals), medications (optional)

## Pipeline
1. **Ingest**
   - Read raw CSVs from `/data_raw`
2. **Validate & Clean**
   - Standardize column names and datatypes
   - Filter invalid encounter date ranges
   - Handle missingness and duplicates
   - Create encounter-level features (length of stay, readmission window)
3. **Curate**
   - Output cleaned tables to `/data_clean`
4. **Load to SQL**
   - Create tables in Postgres/SQLite using `/sql/schema.sql`
5. **Analyze & Report**
   - Run analytic queries in `/sql/queries`
   - Export final tables (CSV) for dashboards in `/reports` or `/dashboards`

## Data Quality Checks (examples)
- % missing key fields by table (patient_id, encounter_id, encounter_start/end)
- duplicate patient_ids and encounter_ids
- encounters where end < start or extreme LOS outliers
- observations outside encounter windows
- implausible values (e.g., negative lab values, impossible vitals)

## Clinical / Research Questions Answered
- Data completeness by table and by month
- Average length of stay by condition category
- 30-day readmission rate overall and by age group
- Encounter volume trends over time
- Lab/vital measurement coverage per encounter (e.g., % encounters with BP recorded)

## How to Run
### Option A: Quickstart (SQLite)
1. Put raw CSVs in `data_raw/`
2. Run `python -m venv .venv && source .venv/bin/activate && pip install -r requirements.txt`
3. `python src/ingest_clean.py`
4. `python src/load_sqlite.py`
5. Run queries: `sqlite3 ehr.db < sql/queries/readmissions.sql`

### Option B: Postgres (recommended)
- Configure `.env`
- `python src/load_postgres.py`
- Run queries in `/sql/queries`

## Repo Structure
- `data_raw/` raw Synthea CSVs (or small sample only)
- `data_clean/` cleaned outputs
- `sql/schema.sql` table definitions + indexes
- `sql/queries/` reporting queries used in this project
- `src/` pipeline code
- `dashboards/` screenshots or exported visuals
- `reports/` final CSVs for dashboarding

## Results (Screenshots)
Add:
- KPI summary screenshot
- Data quality summary table
- One trend chart (encounters over time)

## Limitations
- Synthetic EHR data does not capture full complexity of real hospital EHR workflows
- Coding systems simplified (ICD mapping may be incomplete)
- Results intended for demo/training purposes only

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.



## Next Steps
- Add unit tests for validation rules
- Add orchestration (scheduled runs) via cron/Prefect
